---
organizations:
  - name: NYU
    url: ""
superuser: true
authors:
  - admin
title:
role: Faculty Fellow
avatar_filename: img.jpg
bio: ""
interests:
  - NLP
  - Representaton Learning
  - Interpretability
social:
  - icon: envelope
    icon_pack: fas
    link: "#contact"
  - icon: bluesky
    icon_pack: custom
    link: https://bsky.app/profile/shauli.bsky.social
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/ravfogel
  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.com/citations?user=x09r-T8AAAAJ&hl=en&oi=ao
  - icon: github
    icon_pack: fab
    link: https://github.com/shauli-ravfogel
  - link: https://www.linkedin.com/in/shauli-ravfogel-619712130
    icon: linkedin
    icon_pack: fab
education:
  courses:
    - course: MSc in Computer Science
      institution: Bar Ilan University
      year: ""
    - course: BSc in Computer Science
      institution: Bar Ilan University
      year: ""
    - course: BSc in Chemistry
      institution: Bar Ilan University
      year: ""
email: ""
user_groups:
  - Researchers
  - Visitors
---
Hey! I am a Faculty Fellow at the NYU Center of Data Science. I earned my PhD from the [Natural Language Processing Lab](https://biu-nlp.github.io/) at Bar-Ilan University, supervised by Prof. Yoav Goldberg.

My research focuses on analyzing and controlling the internal representations of generative models, particularly language models. I study how neural networks encode structured information, use it to solve tasks, and represent interpretable concepts. I try---sometimes even successfully---to develop mathematically-principled approaches to interpretability. I am particularly interested in understanding how simple structures, such as concept-aligned linear subspaces, emerge as a byproduct of the language modeling objective, and how we can use such structures to steer and control models.

During my PhD, I’ve worked on techniques to selectively control information in neural representations, with some fun linguistic side tours. More recently, I’ve explored framing LMs as causal models and tackling questions of learnability in a controlled setting.

Feel free to reach out if you have questions about my work or if you're interested in potential collaborations in these areas! You can also find my CV [here](cv/cv.pdf).
