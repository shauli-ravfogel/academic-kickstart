---
organizations:
  - name: Bar Ilan University
    url: ""
superuser: true
authors:
  - admin
title:
role: Computer Science PhD Student
avatar_filename: img.jpg
bio: ""
interests:
  - NLP
  - Representaton Learning
  - Interpretability
social:
  - icon: envelope
    icon_pack: fas
    link: "#contact"
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/ravfogel
  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.com/citations?user=x09r-T8AAAAJ&hl=en&oi=ao
  - icon: github
    icon_pack: fab
    link: https://github.com/shauli-ravfogel
  - link: https://www.linkedin.com/in/shauli-ravfogel-619712130
    icon: linkedin
    icon_pack: fab
education:
  courses:
    - course: MSc in Computer Science
      institution: Bar Ilan University
      year: ""
    - course: BSc in Computer Science
      institution: Bar Ilan University
      year: ""
    - course: BSc in Chemistry
      institution: Bar Ilan University
      year: ""
email: ""
user_groups:
  - Researchers
  - Visitors
---
Hey! I am a Postdoctoral Researcher and Faculty Fellow Faculty Fellow (a linear combination of a faculty and a postdoc) at the NYU Center of Data Science. I had earned my PhD from the [Natural Language Processing Lab](https://biu-nlp.github.io/) at Bar-Ilan University, supervised by [prof. Yoav Goldberg](https://www.cs.bgu.ac.il/~yoavg/uni/). 

My research focuses on understanding, analyzing, and controlling the internal representations of generative models, and in particular language models. I am particularly interested in how neural networks encode structured information in distributed representations, how they use these representations to solve complex tasks, and how we can map these representations back to interpretable concepts or selectively control their content. I try---sometimes even successfully---to develop mathematically-principled approaches to interpretability, steering away from ad-hoc methods. In my master's, I have been studying the ability of NNs to acquire syntax without explicit supervision. 

During my PhD, I have mainly been working on developing techniques to selectively control the information encoded in neural representations, with some fun linguistic side tours. More recently, Iâ€™ve been exploring the framing of language models as causal models and applying controlled approaches to questions of learnability.

Feel free to reach out if you have questions about my work or if you're interested in potential collaborations in these areas! You can also find my CV [here](cv/cv.pdf).
